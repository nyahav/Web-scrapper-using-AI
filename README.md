ğŸŒ AI-Powered Web Scraper with Python, Selenium, and LLM Integration

Welcome to AI Web Scraper, cutting-edge web scraping tool built using Python and powered by Large Language Models (LLM). This project leverages the Selenium library for dynamic website interaction, combined with advanced natural language parsing via LLM to extract valuable information with high accuracy. ğŸš€ ğŸš€ Key Features

Automated Web Scraping: Scrape dynamic web content from any website using Selenium with browser automation.
LLM-Enhanced Parsing: Integrates Ollama LLM (based on Llama3.1) to process and extract structured information from scraped content.
Real-Time Captcha Handling: Ready for captchas with advanced command integration (currently commented out but adaptable).
Text Processing with BeautifulSoup: Cleans and organizes raw HTML content with BeautifulSoup for easy text extraction.
Streamlit UI: A user-friendly interface built with Streamlit for easy web scraping and information extraction without the need for a command line.
Modular Design: Clean and modular codebase that separates scraping, cleaning, and parsing functionalities, making the tool easily extensible and customizable.

ğŸ› ï¸ Technologies Used

Python ğŸ: The core language powering the scraper and the LLM integration.
Selenium ğŸ”—: For browser automation and dynamic web scraping.
Chromium Remote WebDriver ğŸŒ: Seamlessly integrates with a BrightData SuperProxy for web access.
BeautifulSoup ğŸ²: For HTML parsing and content extraction.
LangChain ğŸ§ : Harnesses the power of Ollama's LLM (Llama3.1) for parsing and extracting specific information from raw text.
Streamlit ğŸ“Š: An intuitive UI framework allowing users to interact with the web scraper through a clean, interactive web app.

ğŸ“š How It Works

Scraping Websites: Enter the URL of a website into the Streamlit interface. The tool automates browser interaction using Selenium and extracts the entire pageâ€™s HTML.

Cleaning the Content: The HTML is parsed and cleaned using BeautifulSoup, removing unnecessary elements like scripts and styles to make the text more readable and structured.

Splitting Large Content: Large amounts of content are split into manageable chunks, ready for natural language processing.

LLM Parsing: Using Ollama LLM, users can input a description of what they want to extract from the content. The LLM intelligently parses the provided data, extracting only the relevant information.

ğŸ’¡ Why This Project Stands Out

AI-Driven Parsing: The integration of Large Language Models (LLM) makes this project stand out from traditional scrapers, as it allows for context-aware information extraction.
Automation & Scalability: With Selenium and remote Chromium WebDriver support, this tool can handle complex, JavaScript-heavy sites and automate repetitive tasks at scale.
Human-Like Interaction: Supports real-time captcha solving (feature ready) and natural language queries to mimic human-like interaction with web content.
HR-Ready Skills: This project showcases advanced skills in Python, Selenium, Web Scraping, Natural Language Processing (NLP), and LLM Integrationâ€”making it a valuable addition to any developer's portfolio, especially for roles in AI, Data Science, or Automation.

ğŸš€ Getting Started

Clone this repository:

bash

git clone https://github.com/your-username/ai-web-scraper cd ai-web-scraper

Install the necessary Python packages:

bash

pip install -r requirements.txt

Add your BrightData Proxy credentials in the .env file:

bash

PROXY_URL=http://your-brightdata-proxy-url:port

Run the Streamlit app:

bash

streamlit run main.py

Enter a website URL, and scrape away! ğŸŒ

ğŸ“¦ Folder Structure

bash

ai-web-scraper/ â”‚ â”œâ”€â”€ scrape.py # Core web scraping functionality â”œâ”€â”€ parse.py # LLM-based parsing logic â”œâ”€â”€ main.py # Streamlit interface for user interaction â”œâ”€â”€ requirements.txt # Dependencies for Python environment â”œâ”€â”€ .env # BrightData proxy credentials â””â”€â”€ README.md # Project description

ğŸŒŸ Future Enhancements

Captcha Solving: Integration of automated captcha solving to handle restricted web pages.
Multi-Page Scraping: Adding the ability to scrape and extract data from multiple pages and websites simultaneously.
Advanced Data Processing: Further enhancements to LLM-based data extraction to support more complex information retrieval tasks.

ğŸ¤ Contributions

Contributions are welcome! If you find any issues or have ideas for improvements, feel free to open an issue or submit a pull request. ğŸ§‘â€ğŸ’» About the Author

I am a passionate Python developer focused on leveraging AI and web scraping to solve complex, real-world problems. This project exemplifies my proficiency with automation, data processing, and AI-driven solutions. Feel free to connect with me on LinkedIn or check out my other projects!

Let the power of AI supercharge your web scraping efforts! ğŸŒŸ
